{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div align='center'> Constructing the Dataset </div>\n",
    "\n",
    "----\n",
    "\n",
    "Our goal is to estimate the likelihood of a crime being report / the number of crimes report within a pre-defined distance of a given location over a pre-deterimed time. For example, we would like to say how many crimes will occur within .5miles of a given location over the next hour. In order to model these likelihoods, we need a dataset of locations, times and the number of crimes that occured within that specified parameter. Thusly, the goal of this notebook is to construct such a dataset from raw crime-incident records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach \n",
    "----\n",
    "\n",
    "The approach will be to randomly generate locations and times that fall within a valid domain, and then compute the number of crimes that occur around those points. Since we only have reports of crimes that occur within the city of los angeles, we need a way to generate points only within the city limits of LA. Luckily I was able to find geo-json data describing the los angeles city limits and shapely is able to do the rest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "\n",
    "geometries = [os.path.abspath(os.getcwd() + \\\n",
    "                              '/../CrymeClarity/crymeweb/regions/migrations/fixtures/city_of_los_angeles_geometry.json')]\n",
    "\n",
    "\n",
    "class GeometricDomain:\n",
    "    included_geometries = {}\n",
    "\n",
    "    def __init__(self, geoms):\n",
    "        for geom in geoms:\n",
    "\n",
    "            with open(geom, 'r') as geom_file:\n",
    "                polygon_coords = json.loads(geom_file.read())['geometries'][0]['coordinates'][0][0]\n",
    "\n",
    "            lats_vect = np.array([coord[0] for coord in polygon_coords])\n",
    "            lons_vect = np.array([coord[1] for coord in polygon_coords])\n",
    "            polygon = Polygon(np.column_stack((lons_vect, lats_vect)))\n",
    "\n",
    "            self.included_geometries[geom] = {\n",
    "                'polygon_coords': polygon_coords,\n",
    "                'lats_vect': lats_vect,\n",
    "                'lons_vect': lons_vect,\n",
    "                'polygon': polygon,\n",
    "            }\n",
    "\n",
    "    def get_bounding_box(self):\n",
    "        max_lat = max([self.included_geometries[geometry]['lats_vect'].max()\n",
    "                       for geometry in self.included_geometries])\n",
    "        min_lat = min([self.included_geometries[geometry]['lats_vect'].min()\n",
    "                       for geometry in self.included_geometries])\n",
    "        max_long = max([self.included_geometries[geometry]['lons_vect'].max()\n",
    "                        for geometry in self.included_geometries])\n",
    "        min_long = min([self.included_geometries[geometry]['lons_vect'].min()\n",
    "                        for geometry in self.included_geometries])\n",
    "\n",
    "        return min_lat, max_lat, min_long, max_long\n",
    "\n",
    "    def in_domain(self, y, x):\n",
    "        point = Point(x, y)\n",
    "        for geometry in self.included_geometries:\n",
    "            if self.included_geometries[geometry]['polygon'].contains(point):\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our domain issue solved, lets generate latitude, longitude and timestamps all from a uniform distribution. For our timestamp domain, lets use the last year as our domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "def generate_location_times(min_lat, max_lat, min_long, max_long, td_size, domain, n_samples):\n",
    "    samples = []\n",
    "    gd = domain\n",
    "    while len(samples) < n_samples:\n",
    "        lat = random.uniform(min_lat, max_lat)\n",
    "        long = random.uniform(min_long, max_long)\n",
    "        if gd.in_domain(lat, long):\n",
    "            ts = datetime.datetime(year=2018, month=1, day=1) + datetime.timedelta(days=random.uniform(0,td_size))\n",
    "            samples.append([long, lat, ts])\n",
    "            \n",
    "    return np.array(samples)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.050648853899325, -118.55450142024317,\n",
       "        datetime.datetime(2018, 2, 19, 23, 50, 58, 247868)],\n",
       "       [34.265093314007885, -118.3830286792221,\n",
       "        datetime.datetime(2018, 11, 26, 9, 16, 18, 124628)],\n",
       "       [34.17513089828658, -118.64807166440373,\n",
       "        datetime.datetime(2018, 1, 18, 22, 43, 37, 845688)],\n",
       "       ...,\n",
       "       [34.12677444909474, -118.21297303420394,\n",
       "        datetime.datetime(2018, 11, 25, 17, 21, 55, 456266)],\n",
       "       [34.09006294613667, -118.4065968498316,\n",
       "        datetime.datetime(2018, 7, 10, 5, 25, 12, 224171)],\n",
       "       [34.199823852608866, -118.62464589177222,\n",
       "        datetime.datetime(2018, 12, 7, 6, 10, 28, 785824)]], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd = GeometricDomain(geometries)\n",
    "generate_location_times(-118.6681776, -118.1552948, 33.7036216, 34.337306, 444, gd, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, lets write this up as a management command for our django app."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
